{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello\" 0\n",
      "\"    \" 6\n",
      "\"World\" 10\n",
      "\"!\" 15\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('Hello     World!')\n",
    "for token in doc:\n",
    "    print('\"' + token.text + '\"', token.idx)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are apples.\n",
      "These are oranges.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"These are apples. These are oranges.\")\n",
    " \n",
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Next', 'JJ'), ('week', 'NN'), ('I', 'PRP'), (\"'ll\", 'MD'), ('be', 'VB'), ('in', 'IN'), ('Madrid', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "print([(token.text, token.tag_) for token in doc])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next week DATE\n",
      "Madrid GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Next', 'JJ', 'B-DATE'), ('week', 'NN', 'I-DATE'), ('I', 'PRP', 'O'), (\"'ll\", 'MD', 'O'), ('be', 'VB', 'O'), ('in', 'IN', 'O'), ('Madrid', 'NNP', 'B-GPE'), ('.', '.', 'O')]\n",
      "(S\n",
      "  (DATE Next/JJ week/NN)\n",
      "  I/PRP\n",
      "  'll/MD\n",
      "  be/VB\n",
      "  in/IN\n",
      "  (GPE Madrid/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree\n",
    " \n",
    " \n",
    "doc = nlp(\"Next week I'll be in Madrid.\")\n",
    "iob_tagged = [\n",
    "    (\n",
    "        token.text, \n",
    "        token.tag_, \n",
    "        \"{0}-{1}\".format(token.ent_iob_, token.ent_type_) if token.ent_iob_ != 'O' else token.ent_iob_\n",
    "    ) for token in doc\n",
    "]\n",
    " \n",
    "print(iob_tagged)\n",
    " \n",
    "# In case you like the nltk.Tree format\n",
    "print(conlltags2tree(iob_tagged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.20778  -2.4151    0.36605   2.0139   -0.23752  -3.1952   -0.2952\n",
      "  1.2272   -3.4129   -0.54969   0.32634  -1.0813    0.55626   1.5195\n",
      "  0.97797  -3.1816   -0.37207  -0.86093   2.1509   -4.0845    0.035405\n",
      "  3.5702   -0.79413  -1.7025   -1.6371   -3.198    -1.9387    0.91166\n",
      "  0.85409   1.8039   -1.103    -2.5274    1.6365   -0.82082   1.0278\n",
      " -1.705     1.5511   -0.95633  -1.4702   -1.865    -0.19324  -0.49123\n",
      "  2.2361    2.2119    3.6654    1.7943   -0.20601   1.5483   -1.3964\n",
      " -0.50819   2.1288   -2.332     1.3539   -2.1917    1.8923    0.28472\n",
      "  0.54285   1.2309    0.26027   1.9542    1.1739   -0.40348   3.2028\n",
      "  0.75381  -2.7179   -1.3587   -1.1965   -2.0923    2.2855   -0.3058\n",
      " -0.63174   0.70083   0.16899   1.2325    0.97006  -0.23356  -2.094\n",
      " -1.737     3.6075   -1.511    -0.9135    0.53878   0.49268   0.44751\n",
      "  0.6315    1.4963    4.1725    2.1961   -1.2409    0.4214    2.9678\n",
      "  1.841     3.0133   -4.4652    0.96521  -0.29787   4.3386   -1.2527\n",
      " -1.7734   -3.5637   -0.20035  -3.3013    0.99951  -0.92888  -0.94594\n",
      "  1.5124   -3.9385    2.7935   -3.1042    3.3382    0.54513  -0.37663\n",
      "  2.5151    0.51468  -0.88907   1.011     3.4705   -3.6037    1.3702\n",
      "  2.3468    1.6674    1.3904   -2.8112    2.237    -1.0344   -0.57164\n",
      "  1.0641   -1.6919    1.958    -0.78305   0.14741   0.51083   1.8278\n",
      " -0.69638   0.90548   0.62282  -1.8315   -2.8587    0.48424  -2.0527\n",
      " -0.53808  -2.3472    1.0354   -1.8257   -0.3892   -0.24943   0.8651\n",
      " -1.5195    1.2166   -2.698    -0.96698   2.2175   -0.16089  -0.49677\n",
      " -0.19646   1.3284    4.0824    1.3919    0.80669  -1.0316   -0.28056\n",
      " -1.8632    0.47716  -0.53628   1.3853   -2.1755   -0.2354    2.4933\n",
      " -0.87255   1.4493   -0.10778  -0.44159   1.3462    4.4211   -1.8385\n",
      "  0.3985    0.47637  -0.60074   3.3583   -0.15006  -0.40495   2.7225\n",
      " -1.6297    0.86797  -4.1445   -2.7793    1.1535   -0.011691  0.9792\n",
      " -1.0141    0.80134   0.43642   1.4337    2.8927    0.82871  -1.1827\n",
      " -1.3838    2.3903   -0.89323   1.1461   -1.7435    0.8654   -0.27075\n",
      " -0.78698   1.5631   -0.5923    0.098082 -0.26682   1.6282   -0.77495\n",
      "  3.2552    1.7964   -1.4314    1.2336    2.3102   -1.6328    2.8366\n",
      " -0.71384   0.43967   1.5627    3.079    -0.922    -0.43981  -0.7659\n",
      "  1.9362   -2.2479    1.041     0.63206   1.5855    3.4097   -2.9204\n",
      " -1.4751   -0.59534  -1.688    -4.1362    2.745    -2.8515    3.6509\n",
      " -0.66993  -2.8794    2.0733    1.1779   -2.0307    2.595    -0.12246\n",
      "  1.5844    1.1855    0.022385 -2.2916   -2.2684   -2.7537    0.34981\n",
      " -4.6243   -0.96521  -1.1435   -2.8894   -0.12619   2.9577   -1.7227\n",
      "  0.24757   1.2149    3.5349   -0.95802   0.080346 -1.6553   -0.6734\n",
      "  2.2918   -1.8229   -1.1336    1.8884    2.4789   -0.66061   2.0529\n",
      " -0.76687   0.32362  -2.2579    0.91278   0.36231   0.61562  -0.15396\n",
      " -0.42917  -0.89848   0.17298  -0.76978  -2.0222   -1.7127   -1.5632\n",
      "  0.56631  -1.354     2.6261    1.9156   -1.5651    1.8315   -1.4257\n",
      " -1.6861   -0.51953   1.7635   -0.50722   1.388    -1.1012  ]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "print(nlp.vocab['banana'].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queen', 'man', 'king', 'woman', 'he', 'nothinâ€™', \"'cause\", \"'Cause\", 'He', 'That']\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    " \n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    " \n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "queen = nlp.vocab['queen'].vector\n",
    "king = nlp.vocab['king'].vector\n",
    " \n",
    "# We now need to find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
    "maybe_king = man - woman + queen\n",
    "computed_similarities = []\n",
    " \n",
    "for word in nlp.vocab:\n",
    "    # Ignore words without vectors\n",
    "    if not word.has_vector:\n",
    "        continue\n",
    " \n",
    "    similarity = cosine_similarity(maybe_king, word.vector)\n",
    "    computed_similarities.append((word, similarity))\n",
    " \n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "print([w[0].text for w in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
