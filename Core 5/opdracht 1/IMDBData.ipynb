{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP project\n",
    "\n",
    "In this project I will use NLP on the IMDB dataset. The first step is to read this dataset and prepare it for the NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.models import Model\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Read in the dataset\n",
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase\n",
    "data['review'] = data['review'].apply(lambda x: x.lower())\n",
    "\n",
    "# Tokenize the text\n",
    "review_tokenizer = Tokenizer()\n",
    "review_tokenizer.fit_on_texts(data['review'])\n",
    "sentiment_tokenizer = Tokenizer()\n",
    "sentiment_tokenizer.fit_on_texts(data['sentiment'])\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "review_sequences = review_tokenizer.texts_to_sequences(data['review'])\n",
    "sentiment_sequences = sentiment_tokenizer.texts_to_sequences(data['sentiment'])\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_sequence_length = 100\n",
    "review_data = pad_sequences(review_sequences, maxlen=max_sequence_length, padding='post')\n",
    "sentiment_data = pad_sequences(sentiment_sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we first read in the dataset. We then convert the text to lowercase and tokenize the text using Keras' Tokenizer class. We also pad the sequences to a fixed length of 100.\n",
    "\n",
    "Next, we split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   34,  1637,     9, ...,   125,  4103,   486],\n",
       "       [ 9719,    31,     1, ...,  1977,    69,   221],\n",
       "       [ 3059,    12,  2971, ...,    63,    16,   350],\n",
       "       ...,\n",
       "       [   26,     3,  1156, ..., 22840,     2,  6050],\n",
       "       [    5,    68,   135, ...,    67,   739,    42],\n",
       "       [  699,   479,    11, ...,   794,    11,    17]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [2, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(review_data, sentiment_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our encoder and decoder models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input sequence\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "# Define output sequence\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# Define encoder embedding layer\n",
    "encoder_embedding = Embedding(len(review_tokenizer.word_index) + 1, 256)\n",
    "encoder_embedding_output = encoder_embedding(encoder_inputs)\n",
    "\n",
    "# Define encoder LSTM layer\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding_output)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define decoder embedding layer\n",
    "decoder_embedding = Embedding(len(sentiment_tokenizer.word_index) + 1, 256)\n",
    "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# Define decoder LSTM layer\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding_output, initial_state=encoder_states)\n",
    "\n",
    "# Define output layer\n",
    "decoder_dense = Dense(len(sentiment_tokenizer.word_index) + 1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we define the input and output sequences, as well as the embedding and LSTM layers for the encoder and decoder. We also define the output layer and the entire model.\n",
    "\n",
    "We can now compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Warmtebron\\AppData\\Local\\Temp\\ipykernel_4400\\2935895805.py:34: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=generate_batch(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 156 batches). You may need to use the repeat() function when building your dataset.\n",
      "625/625 [==============================] - 698s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.9067e-08 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 525s 840ms/step - loss: 3.3731e-08 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 517s 827ms/step - loss: 1.8059e-08 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 516s 826ms/step - loss: 1.1045e-08 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 515s 825ms/step - loss: 7.1988e-09 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 515s 824ms/step - loss: 5.9937e-09 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 515s 824ms/step - loss: 4.8193e-09 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 517s 827ms/step - loss: 3.9747e-09 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 511s 817ms/step - loss: 1.9438e-09 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 510s 817ms/step - loss: 1.2041e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x275f73ba3b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Define generator for training data\n",
    "def generate_batch(X=X_train, y=y_train, batch_size=batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            encoder_input_data = X[i:i + batch_size]\n",
    "            decoder_input_data = y[i:i + batch_size, :-1]\n",
    "            decoder_output_data = y[i:i + batch_size, 1:]\n",
    "            encoder_input_data = np.array(encoder_input_data)\n",
    "            decoder_input_data = np.array(decoder_input_data)\n",
    "            decoder_output_data = np.array(decoder_output_data)\n",
    "            decoder_output_data = to_categorical(decoder_output_data, num_classes=len(sentiment_tokenizer.word_index) + 1)\n",
    "            yield ([encoder_input_data, decoder_input_data], decoder_output_data)\n",
    "\n",
    "# Define generator for validation data\n",
    "def generate_validation(X=X_val, y=y_val):\n",
    "    encoder_input_data = np.array(X)\n",
    "    decoder_input_data = np.array(y[:, :-1])\n",
    "    decoder_output_data = np.array(y[:, 1:])\n",
    "    decoder_output_data = to_categorical(decoder_output_data, num_classes=len(sentiment_tokenizer.word_index) + 1)\n",
    "    return ([encoder_input_data, decoder_input_data], decoder_output_data)\n",
    "\n",
    "# Train model\n",
    "model.fit_generator(generator=generate_batch(),\n",
    "                    steps_per_epoch=len(X_train)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=generate_validation(),\n",
    "                    validation_steps=len(X_val)//batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we define the batch size and number of epochs. We also define the generators for the training and validation data. The generate_batch function generates batches of data for the training data. The generate_validation function generates data for the validation data. We then train the model using the fit_generator function.\n",
    "\n",
    "Finally, we can make predictions using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define encoder model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Define decoder inputs\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding_output, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input sequence to get the encoder states\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character\n",
    "    target_seq[0, 0] = sentiment_tokenizer.word_index['<start>']\n",
    "\n",
    "    # Generate output sequence\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = sentiment_tokenizer.index_word[sampled_token_index]\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character\n",
    "        if (sampled_token == '<end>' or len(decoded_sentence) > max_sequence_length):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "            # Update the target sequence\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we define a function sequence_to_text that converts a sequence to text. We then generate some translations for the validation data by selecting a random input sequence, using the decode_sequence function to generate the predicted output sequence, and then converting the sequences to text. We print the input, target, and predicted sequences for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_text(sequence, tokenizer):\n",
    "    \"\"\"\n",
    "    Converts a sequence of integers to its corresponding text sequence.\n",
    "    \n",
    "    Args:\n",
    "    - sequence (np.array): A sequence of integers.\n",
    "    - tokenizer (keras.preprocessing.text.Tokenizer): A tokenizer fitted on the text data.\n",
    "    \n",
    "    Returns:\n",
    "    - A string representing the text sequence.\n",
    "    \"\"\"\n",
    "    text = tokenizer.sequences_to_texts([sequence])[0]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 405ms/step\n",
      "Review: This movie is fantastic. I loved every minute of it!\n",
      "Predicted sentiment: \n"
     ]
    }
   ],
   "source": [
    "# Define a new review\n",
    "new_review = \"This movie is fantastic. I loved every minute of it!\"\n",
    "\n",
    "# Convert the review to a sequence of integers\n",
    "new_review_seq = review_tokenizer.texts_to_sequences([new_review])[0]\n",
    "\n",
    "# Pad the sequence to the same length as the training data\n",
    "new_review_seq = pad_sequences([new_review_seq], maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Use the model to predict the sentiment of the review\n",
    "pred_sentiment_seq = model.predict([new_review_seq, np.zeros((len(new_review_seq), 1))])\n",
    "\n",
    "# Convert the predicted sentiment sequence to text\n",
    "pred_sentiment_text = sequence_to_text(np.argmax(pred_sentiment_seq, axis=2)[0], sentiment_tokenizer)\n",
    "\n",
    "print(\"Review:\", new_review)\n",
    "print(\"Predicted sentiment:\", pred_sentiment_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
